---
title: "Practico Módulo 2: Modelos Lineales"
subtitle: "Programación funcional y estadística avanzada"
author: "Gerardo Esteban, Gómez-Santiago"
date: "January 17, 2025"
toc: true
format: 
  html:
    code-links:
      - text: Video YouTube
        icon: file-code
        href: https://youtu.be/YX1qL_SDntU
      - text: Repositorio GitHub
        icon: file-code
        href: https://github.com/GomezGerardoEsteban/Tidyverso/tree/761537f6add6b0169bed31202597dbfa52588080/PracticosTallerRNivel2/Modulo1
    html-math-method: katex
    code-tools: true
    self-contained: true
execute:
  warning: false
---

La idea de este práctico es poner en práctica elementos del módulo 1 en el que vimos funciones y procesos iterados, con elementos del módulo 2 en el que vimos regresión simple, multiple y tuvimos una breve introducción a regresión logística y modelos panel.

El practico lo desarrollare con la misma base que utilizamos durante la clase pero puedes usar cualquier otra.

## Pasos previos:

- Limpieza del ambiente de trabajo
- Activación de librerias
- Carga de los datos

```{r}

rm(list = ls())

setwd("E:/Documents/Escritorio/tidyverso/tidyverso/cursoRLunes/RLunes/Nivel2")

library(tidyverse)
library(tseries)
library(lmtest)
library(car)

# cargar los datos --------------------------------------------------------

# 'baseN2.RData' es un panel de datos con información del banco mundial.

load(file = "baseN2.RData") # Cargamos los datos de .RData

base1 %>% glimpse()

```

Como lo que tenemos es un panel de datos, vamos a separar la base por años con el comando `split()`

```{r}

base_year <- split(x = base1,        # Base
                   f = base1$date)   # Variable a partir de la cual cortamos la base


```

## Ejercicio 1:

Los modelos de regresión deben cumnplir con ciertos supuestos para garantizar que los estimadores obtenidos son los "MELI" (Mejor Estimador Lineal Insesgado) son cuatro supuestos respecto a los errores y dos supuestos adicionales, uno con respecto a la no multicolinealidad y otro con respecto a la existencia de valores  extremos.
 
Crea una función que reciba un modelo y verifique los supuestos respecto a los errores, el resultado debe ser una tabla  con el resumen de las pruebas, existen varios paquetes que permiten hacer eso, yo te dejo las funciones que yo suelo usar.

- Normalidad: `tseries::jarque.bera.test()`
- Media cero: `t.test(..., mu = 0)`
- Homocedasticidad: `lmtest::bptest()`
- No autocorrelacion: `lmtest::dwtest()`

Si te animas a incorporar el supuesto de multicolinealidad y valores influyentes en la misma tabla, adelante.

```{r}

base <- base_year[[1]]

vector <- c("Inflation", "govSpending", "trade",
            "gdpPerCapita", "gini", "ruralPop")


reg <- lm(formula = base[["growthGdp"]] ~ .,
          data = base[,vector])

summary(reg)

```

Verificación de supuestos

```{r}
# Normalidad

p <- tseries::jarque.bera.test(reg$residuals)

p$p.value

# Media cero

q <- t.test(x = reg$residuals, mu = 0)

q$p.value

# Homocedaticidad

r <- lmtest::bptest(reg)

r$p.value

# No Autocorrelacion

s <- lmtest::dwtest(reg)

s$p.value

```

Creación de función para verificación de supuestos

```{r}

# Creacion de funcion

supuestos_errores <- function(lm){
  
  p <- tseries::jarque.bera.test(lm$residuals)

  q <- t.test(x = lm$residuals, mu = 0)

  r <- lmtest::bptest(lm)

  s <- lmtest::dwtest(lm)
  
  tabla <- tibble(Normalidad = ifelse(p$p.value > 0.05,
                                      "Cumple",
                                      "No Cumple"),
                  Media0 = ifelse(q$p.value > 0.05,
                                      "Cumple",
                                      "No Cumple"),
                  Homocedasticidad = ifelse(r$p.value > 0.05,
                                      "Cumple",
                                      "No Cumple"),
                  No.Autocorrelacion = ifelse(s$p.value > 0.05,
                                      "Cumple",
                                      "No Cumple"))
  
  vector <- round(c(p$p.value, q$p.value, r$p.value, s$p.value),3)
  
  tabla <- rbind(tabla, vector)

  
  return(tabla)
  
  
}

supuestos_errores(reg)


```

## Ejercicio 2:

En clase vimos como correr el mismo modelo (la misma especificacion de variables dependiente e independiente) para distintas bases de datos de manera iterada.

Animate a generar un proceso iterado en el que apliques distintas especificaciones de modelos sobre la misma base de datos. Y si intentas aplicar distintas especificaciones de modelos sobre distintas bases de datos?

Te copio la función y el proceso iterado que utilizamos para el mismo modelo en distintas bases.

```{r}
# Creamos función para obtener resumen en tabla de regresion multiple

regresion_mul <- function (df,         # Base de datos
                           var_dep,    # Variable dependiente
                           vars) {     # Vector con variables independientes
  
    
    # 1. Correr la regresión con lm()
    
    p <- lm(formula = df[[var_dep]] ~ .,
            data = df[,vars])
    
    # 2. Guardar el summary de la regresion
    
    q <- summary(p)
    
    # 3. Crear tabla resumen
    
    coef <- tibble(Nombres = rownames(q$coefficients)[2:(length(vars)+1)],       # Nombres de variables independientes
                   Estimacion = round(q$coefficients[vars, 1], 4),               # Valor de coeficientes independientes
                   p.Valor = round(q$coefficients[vars, 4], 4),                  # P-VAlor de variables independientes
                   R2 = q$r.squared) %>%                                         # R cuadrado de la regresión
      mutate(Significatividad = ifelse(test = p.Valor < 0.05,                    # Variable que resume la significatividad de cada variable independiente
                                       yes = "Significativo",
                                       no = "No Significativo"))
    
    return(coef)                                                                 # Retorna tabla
    
}


regresion_mul(df = base,
              var_dep = "growthGdp",
              vars = c("Inflation", "trade", "govSpending"))


vector0 <- c("Inflation", "trade", "govSpending")
vector1 <- c("Inflation", "trade", "govSpending", "eduSpending", "ruralPop")
vector2 <- c("Inflation", "trade", "govSpending", "eduSpending", "ruralPop", "polar_mean")
vector3 <- c("Inflation", "trade", "govSpending", "eduSpending", "ruralPop", "polar_mean", "gini")


regresiones <- map2(.x = list(vector0, vector1, vector2, vector3),
                    .y = c("0", "1", "2", "3"),
                    .f = ~{
                      
                      regresion_mul(df = base,
                                    var_dep = "growthGdp",
                                    vars = .x) %>% 
                        mutate(vector = .y) %>% 
                        relocate(vector, .before = Nombres)
                      
                      
                    })

regresiones <- regresiones %>% bind_rows()

regresiones

```

## Ejercicio 3:

Existe un paper maravillos de Bertrand & Mullainathan en el que buscan generar evidencia sobre la discriminacion racial en el ambito laboral. Generaron CV falsos pero con caracteristicas que permitian al empleador darse cuenta si el postulante era Negro o Blanco.\
Por suerte dejaron toda esa información a disposición para replicar el análisis. Usando la base 'resume.csv', estima dos modelos logisticos. La variable dependiente es 'received_callback'.

1. El primer modelo usando como variables independientes 'years_experience', 'years_college' y 'race'
2. El segundo modelo usando como variables independientes 'job_city', 'years_experience', 'honors' y 'race'

Cual es mejor segun AIC?

```{r}
# Carga de la base

base_log <- read.csv(file = "resume.csv")

base_log %>% glimpse()

```

Corremos modelo 1 con la especificación de `received_callback` en función de `years_experience`, `years_college` y `race`.

```{r}
# Modelo 1

modelo1 <- glm(formula = as.factor(received_callback) ~ years_college + years_experience + as.factor(race),
               data = base_log,
               family = "binomial")

summary(modelo1)
```

Corremos modelo 2 con la especificación de `received_callback` en función de `years_experience`, `job_city`, `honors` y `race`.

```{r}

# Modelo 2

modelo2 <- glm(formula = as.factor(received_callback) ~ as.factor(job_city) + years_experience + as.factor(honors) + as.factor(race),
               data = base_log,
               family = "binomial")

summary(modelo2)

```

Por el critério de información de Akaike (AIC) el modelo 2 es mejor que el modelo 1.


